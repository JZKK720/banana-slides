# ============================================================
# ğŸ¤– AI æä¾›è€…é…ç½®
# ============================================================
# å¯é€‰å€¼: "gemini" (é»˜è®¤), "openai"
AI_PROVIDER_FORMAT=gemini

# ============================================================
# â˜ï¸ Google Gemini é…ç½® (é»˜è®¤)
# ============================================================
GOOGLE_API_KEY=your-api-key-here
# ä»£ç†ç¤ºä¾‹: https://aihubmix.com/gemini
GOOGLE_API_BASE=https://generativelanguage.googleapis.com
# GenAI (Gemini) è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤300ç§’
GENAI_TIMEOUT=300.0
# GenAI (Gemini) æœ€å¤§é‡è¯•æ¬¡æ•°ï¼ˆåº”ç”¨å±‚å®ç°ï¼‰ï¼Œé»˜è®¤2æ¬¡
GENAI_MAX_RETRIES=2

# AI æ¨¡å‹é…ç½® (Gemini)
TEXT_MODEL=gemini-3-flash-preview
IMAGE_MODEL=gemini-3-pro-image-preview

# ============================================================
# â˜ï¸ OpenAI é…ç½®
# ============================================================
OPENAI_API_KEY=your-api-key-here
# ä»£ç†ç¤ºä¾‹: https://aihubmix.com/v1
OPENAI_API_BASE=https://api.openai.com/v1
# è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤300ç§’
OPENAI_TIMEOUT=300.0
# æœ€å¤šé‡è¯•æ¬¡æ•°ï¼Œå‡å°‘é‡è¯•é¿å…ç´¯ç§¯è¶…æ—¶ï¼Œé»˜è®¤2æ¬¡
OPENAI_MAX_RETRIES=2

# ============================================================
# ğŸ  æœ¬åœ° LLM æœåŠ¡ - Ollama (å¯é€‰æ·»åŠ )
# ============================================================
# å¯ç”¨æ–¹å¼: å°† OPENAI_API_BASE è®¾ç½®ä¸º http://host.docker.internal:11434/v1
#           å°† OPENAI_API_KEY è®¾ç½®ä¸º ollama
#
# å¯åŠ¨ Ollama æœåŠ¡:
#   docker run -d -v ollama:/root/.ollama -p 11434:11434 ollama/ollama
#   ollama pull llama2
#   ollama pull llava
#
OLLAMA_API_BASE=http://host.docker.internal:11434
OLLAMA_TEXT_MODEL=llama2
OLLAMA_IMAGE_MODEL=llava
OLLAMA_TIMEOUT=300.0

# ============================================================
# ğŸ  æœ¬åœ° LLM æœåŠ¡ - LM Studio (å¯é€‰æ·»åŠ )
# ============================================================
# å¯ç”¨æ–¹å¼: å°† OPENAI_API_BASE è®¾ç½®ä¸º http://127.0.0.1:14321/api/v1
#           å°† OPENAI_API_KEY è®¾ç½®ä¸º Bearer token (è‹¥éœ€è¦è®¤è¯)
#
# ä¸‹è½½åœ°å€: https://lmstudio.ai/
# API æ–‡æ¡£: LM Studio æä¾› REST API æ”¯æŒ
#
# è¯·æ±‚æ ¼å¼ç¤ºä¾‹:
# curl http://127.0.0.1:14321/api/v1/chat \
#   -H "Authorization: Bearer $LM_API_TOKEN" \
#   -H "Content-Type: application/json" \
#   -d '{
#     "model": "ibm/granite-4-micro",
#     "input": "Write a short haiku about sunrise."
#   }'
#
LM_STUDIO_API_BASE=http://127.0.0.1:14321/api/v1
LM_STUDIO_API_TOKEN=your-lm-studio-token-if-required
LM_STUDIO_TEXT_MODEL=ibm/granite-4-micro
LM_STUDIO_IMAGE_MODEL=local-vision-model
LM_STUDIO_TIMEOUT=300.0

# ============================================================
# ğŸ“Š æœ¬åœ°è§†è§‰å’Œ OCR æ¨¡å‹é…ç½® (å¯é€‰)
# ============================================================
VISION_MODEL_SERVICE=ollama
VISION_MODEL_ENDPOINT=http://host.docker.internal:11434
VISION_MODEL_NAME=llava

# OCR æœåŠ¡é…ç½®: ollama (æœ¬åœ°-æ¨è), baidu (äº‘ç«¯), paddleocr (æœ¬åœ°), tesseract (æœ¬åœ°)
# æ³¨: è‹¥ä½¿ç”¨ OCR_SERVICE=ollamaï¼Œåˆ™ OCR_ENDPOINT åº”æŒ‡å‘ Ollama (11434)
#     è‹¥ä½¿ç”¨ OCR_SERVICE=paddleocrï¼Œåˆ™ OCR_ENDPOINT åº”æŒ‡å‘ PaddleOCR (8000)
OCR_SERVICE=ollama
OCR_ENDPOINT=http://host.docker.internal:11434
OCR_API_KEY=

# Ollama OCR é…ç½® (ä½¿ç”¨è§†è§‰æ¨¡å‹è¿›è¡Œ OCR)
OCR_MODEL_OLLAMA=llava
OLLAMA_OCR_ENABLE=true
OLLAMA_OCR_MODEL=llava

# PaddleOCR é…ç½® (å¯é€‰æ›¿ä»£æ–¹æ¡ˆ)
# å¯ç”¨æ–¹æ³•: è®¾ç½® OCR_SERVICE=paddleocr å¹¶å¯ç”¨ä¸‹é¢çš„é…ç½®
# docker run -d -p 8000:8000 paddleocr/paddleocr-api:latest
PADDLEOCR_ENDPOINT=http://host.docker.internal:8000
PADDLEOCR_ENABLE=false

# Tesseract OCR é…ç½® (å¯é€‰æ›¿ä»£æ–¹æ¡ˆ)
TESSERACT_PATH=/usr/bin/tesseract
TESSERACT_ENABLE=false

# ============================================================
# ğŸ–¼ï¸ å›¾ç‰‡æè¿°å’Œè¯†åˆ«é…ç½®
# ============================================================
IMAGE_CAPTION_MODEL=gemini-3-flash-preview
LOCAL_IMAGE_CAPTION_MODEL=llava
LOCAL_IMAGE_CAPTION_ENDPOINT=http://host.docker.internal:11434

# ============================================================
# ğŸ“„ æ–‡æ¡£è§£ææœåŠ¡é…ç½®
# ============================================================
MINERU_TOKEN=eyJ0eXBlIjoiSldUIiwiYWxnIjoiSFM1MTIifQ.eyJqdGkiOiI0ODkwMDAwNSIsInJvbCI6IlJPTEVfUkVHSVNURVIiLCJpc3MiOiJPcGVuWExhYiIsImlhdCI6MTc2NzU5MjM3NCwiY2xpZW50SWQiOiJsa3pkeDU3bnZ5MjJqa3BxOXgydyIsInBob25lIjoiMTk5MjQyMjYyNTgiLCJvcGVuSWQiOm51bGwsInV1aWQiOiJiNDJkYmE3Yy1kZGY0LTRkMGUtYTY0OS0yMjg2MjMwNjY0Y2EiLCJlbWFpbCI6IiIsImV4cCI6MTc2ODgwMTk3NH0.oDW3w29YeiLLyL6x5JDKo2ZmZf5VRvcH4BpNG-mKR-Jyp6AxuGiLtiDohlD6WYLwJb7fyE5X1bgbZQ75ZwDthw
MINERU_API_BASE=https://mineru.net

# ============================================================
# ğŸ”¤ ç™¾åº¦ OCR é…ç½®
# ============================================================
BAIDU_OCR_API_KEY=you-baidu-api-key

# ============================================================
# Flask é…ç½®
# ============================================================
LOG_LEVEL=INFO
FLASK_ENV=production
SECRET_KEY=your-secret-key-change-this-in-production
BACKEND_PORT=5101

CORS_ORIGINS=*

MAX_DESCRIPTION_WORKERS=5
MAX_IMAGE_WORKERS=8

# ============================================================
# ğŸŒ è¾“å‡ºè¯­è¨€é…ç½®
# ============================================================
OUTPUT_LANGUAGE=zh

# ============================================================
# ğŸ§  æ¨ç†æ¨¡å¼é…ç½®
# ============================================================
ENABLE_TEXT_REASONING=false
TEXT_THINKING_BUDGET=5000

ENABLE_IMAGE_REASONING=false
IMAGE_THINKING_BUDGET=5000

# ============================================================
# ğŸŒ é•œåƒæºé…ç½®ï¼ˆå›½å†…ç”¨æˆ·å¦‚é‡ç½‘ç»œé—®é¢˜ï¼Œå–æ¶ˆä»¥ä¸‹æ³¨é‡Šå³å¯ä½¿ç”¨å›½å†…é•œåƒæºï¼‰
# ============================================================

# #  Docker Hub é•œåƒæºï¼ˆæ³¨æ„æœ«å°¾æ–œæ ï¼‰
# DOCKER_REGISTRY=docker.1ms.run/

# # GitHub Container Registry é•œåƒæºï¼ˆæ³¨æ„æœ«å°¾æ–œæ ï¼‰
# GHCR_REGISTRY=ghcr.nju.edu.cn/

# # Debian apt é•œåƒæº
# APT_MIRROR=mirrors.aliyun.com

# # PyPI é•œåƒæº
# PYPI_INDEX_URL=https://mirrors.cloud.tencent.com/pypi/simple

# # npm é•œåƒæºï¼ˆæ³¨æ„æœ«å°¾æ–œæ ï¼‰
# NPM_REGISTRY=https://registry.npmmirror.com/

# ============================================================
# âš™ï¸ å¿«é€Ÿé…ç½®ç¤ºä¾‹
# ============================================================
# 
# ç¤ºä¾‹ 1: ä½¿ç”¨ Google Gemini (äº‘ç«¯, é»˜è®¤)
# ============================================================
# AI_PROVIDER_FORMAT=gemini
# GOOGLE_API_KEY=your-api-key
# TEXT_MODEL=gemini-3-flash-preview
# IMAGE_MODEL=gemini-3-pro-image-preview
#
# ç¤ºä¾‹ 2: ä½¿ç”¨ OpenAI (äº‘ç«¯)
# ============================================================
# AI_PROVIDER_FORMAT=openai
# OPENAI_API_KEY=sk-...
# OPENAI_API_BASE=https://api.openai.com/v1
#
# ç¤ºä¾‹ 3: ä½¿ç”¨ Ollama (æœ¬åœ°)
# ============================================================
# å¯åŠ¨ Ollama:
#   docker run -d -v ollama:/root/.ollama -p 11434:11434 ollama/ollama
#   ollama pull llama2
#   ollama pull llava
#
# é…ç½®:
# AI_PROVIDER_FORMAT=openai
# OPENAI_API_BASE=http://host.docker.internal:11434/v1
# OPENAI_API_KEY=ollama
#
# ç¤ºä¾‹ 4: ä½¿ç”¨ LM Studio (æœ¬åœ°)
# ============================================================
# å¯åŠ¨ LM Studio:
#   ä¸‹è½½: https://lmstudio.ai/
#   å¯åŠ¨åè®¿é—®: http://127.0.0.1:14321
#
# é…ç½®:
# AI_PROVIDER_FORMAT=openai
# OPENAI_API_BASE=http://127.0.0.1:14321/api/v1
# OPENAI_API_KEY=your-token-if-required
# 
# ä½¿ç”¨ç¤ºä¾‹:
# curl http://127.0.0.1:14321/api/v1/chat \
#   -H "Authorization: Bearer $OPENAI_API_KEY" \
#   -H "Content-Type: application/json" \
#   -d '{
#     "model": "ibm/granite-4-micro",
#     "input": "Your prompt here"
#   }'
#
